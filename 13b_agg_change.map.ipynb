{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86734369-22ad-49b5-96bd-e24e095bbdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1167788, 15)\n"
     ]
    }
   ],
   "source": [
    "version = 'v20250521'\n",
    "\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold,cross_val_predict\n",
    "from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# discretinized points\n",
    "df = pd.read_parquet('./material/agg_pixel_change.pq')\n",
    "geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "df = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:3035\")\n",
    "print(df.shape)\n",
    "\n",
    "# # samples # in the end, we didn't opt for sample vs. pixel comparison\n",
    "# spl = pd.read_parquet(f'./material/srs_agg_{version}.pq')\n",
    "# geometry = [Point(xy) for xy in zip(spl['lon_mean'], spl['lat_mean'])]\n",
    "# spl = gpd.GeoDataFrame(spl, geometry=geometry, crs=\"EPSG:4032\")\n",
    "# spl = spl.to_crs('EPSG:3035')\n",
    "\n",
    "sizes = [2.5, 10, 40, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70f155b-375c-4222-8878-ce2bd4ba89fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 -------------------------------\n",
      "10 -------------------------------\n",
      "40 -------------------------------\n",
      "200 -------------------------------\n"
     ]
    }
   ],
   "source": [
    "for isize in sizes:\n",
    "    print(isize, '-------------------------------')\n",
    "    plg = gpd.read_file(f'./material/grid_all.{isize}km_agg.{version}.gpkg')\n",
    "    df = gpd.sjoin(df, plg[['geometry']], how=\"inner\", predicate=\"intersects\")\n",
    "    df = df.rename(columns={'index_right':f'id_{isize}'})\n",
    "    \n",
    "    # # randomly select 2500 per id_isize as 1, others 0\n",
    "    # idx = (df.groupby(f'id_{isize}', group_keys=False)\n",
    "    #          .apply(lambda g: g.sample(n=min(2500, len(g)), random_state=42))\n",
    "    #          .index)\n",
    "    # df[f'is_{isize}'] = df.index.isin(idx).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754294b-dcd9-46b1-918b-db90b08d1e68",
   "metadata": {},
   "source": [
    "## spatial aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fa585f-7fa2-459f-a6c0-5ee2483322bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 -------------------------------\n",
      "10 -------------------------------\n",
      "40 -------------------------------\n",
      "200 -------------------------------\n"
     ]
    }
   ],
   "source": [
    "# point\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "# correlation function\n",
    "def exponential_model(h, nugget, sill, range_):\n",
    "    return nugget + (sill - nugget) * (1 - np.exp(-h / range_))\n",
    "\n",
    "def correlation_function(h, nugget, sill, range_):\n",
    "    # Calculate the variogram value at distance h\n",
    "    gamma_h = exponential_model(h, nugget, sill, range_)\n",
    "    # Calculate and return the correlation function value\n",
    "    return (sill - gamma_h) / sill\n",
    "\n",
    "params_es = np.array([0.74285565, 1.00000001, 5.99345285])\n",
    "params_de = np.array([0.72415892,  1.00000001, 10.60109839])\n",
    "\n",
    "# get the map based spatial aggregates\n",
    "for isize in sizes:\n",
    "    ttprint(isize, '-------------------------------')\n",
    "    plg = gpd.read_file(f'./material/grid_all.{isize}km_agg.{version}.gpkg')\n",
    "    plg_id_col = f'id_{isize}'\n",
    "    group_ids = df[plg_id_col].dropna().unique().tolist()\n",
    "\n",
    "    for id_val in group_ids:\n",
    "        ipnt = df.loc[df[plg_id_col] == id_val]\n",
    "        if ipnt.empty:\n",
    "            continue\n",
    "        \n",
    "        params_vg = params_es if ipnt.iloc[0]['nuts0'] == 'ES' else params_de\n",
    " \n",
    "        # distance\n",
    "        coords = np.array([(geom.x, geom.y) for geom in ipnt.geometry])\n",
    "        dist_matrix = distance_matrix(coords, coords) / 1000\n",
    "        corr_matrix = correlation_function(dist_matrix, *params_vg)\n",
    "        np.fill_diagonal(corr_matrix, 1.0)\n",
    "        \n",
    "        # variances\n",
    "        std09 = ipnt['pred_std_2009'].to_numpy()\n",
    "        var_matrix_2009 = np.outer(std09, std09) * corr_matrix\n",
    "        std18 = ipnt['pred_std_2018'].to_numpy()\n",
    "        var_matrix_2018 = np.outer(std18, std18) * corr_matrix\n",
    "\n",
    "        n = len(ipnt)\n",
    "        agg_var_2009 = np.nansum(var_matrix_2009) / (n * n)\n",
    "        agg_var_2018 = np.nansum(var_matrix_2018) / (n * n)\n",
    "        \n",
    "        # means\n",
    "        m09 = ipnt['pred_2009'].mean()\n",
    "        m18 = ipnt['pred_2018'].mean()\n",
    "\n",
    "        # write back (index == id by design)\n",
    "        plg.loc[plg.index == id_val, 'var_2009'] = agg_var_2009\n",
    "        plg.loc[plg.index == id_val, 'var_2018'] = agg_var_2018\n",
    "        plg.loc[plg.index == id_val, 'mean_2009'] = m09\n",
    "        plg.loc[plg.index == id_val, 'mean_2018'] = m18\n",
    "       \n",
    "    # Merge back into plg\n",
    "    plg['change'] = plg['mean_2018'] - plg['mean_2009']\n",
    "    plg['signal'] = plg['change'].abs()\n",
    "    plg['noise']  = np.sqrt(plg['var_2009'] + plg['var_2018'])\n",
    "\n",
    "    plg.to_file(f'./material/grid_all.{isize}km_agg.calc.{version}.gpkg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ddd13-8cf9-4ab9-8edb-799d33b7d206",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate SNR, for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb533c3-89c2-48aa-bb6b-0b8bf787237b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:34:19] 2.5 -------------------------------\n",
      "[08:35:07] 10 -------------------------------\n",
      "[08:35:10] 40 -------------------------------\n",
      "[08:35:11] 200 -------------------------------\n"
     ]
    }
   ],
   "source": [
    "for isize in sizes:\n",
    "    ttprint(isize, '-------------------------------')\n",
    "    plg = gpd.read_file(f'./material/grid_all.{isize}km_agg.calc.{version}.gpkg')\n",
    "    plg['snr'] = plg['signal']/plg['noise']\n",
    "    plg = plg.loc[plg['snr'].notna()]\n",
    "    plg.to_file(f'./material/grid_all.{isize}km_agg.vlz.{version}.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e1ae826-252a-4dc0-b4f3-5884acac667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plg.to_file(f'./material/grid_all.200km_agg.vlz.20251017.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba0563-3bc3-4d77-88d7-eba3256953f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
