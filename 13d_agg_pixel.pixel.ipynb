{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86734369-22ad-49b5-96bd-e24e095bbdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "version = 'v20250521'\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold,cross_val_predict\n",
    "from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754294b-dcd9-46b1-918b-db90b08d1e68",
   "metadata": {},
   "source": [
    "## creat pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fa585f-7fa2-459f-a6c0-5ee2483322bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import rasterio\n",
    "# from rasterio.mask import mask\n",
    "# import os\n",
    "# os.environ['USE_PYGEOS'] = '0'\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from skmap.misc import find_files, GoogleSheet, ttprint\n",
    "\n",
    "# rtif = 'http://192.168.1.30:8333/ai4sh-landmasked/air.temp/clm_air.temp_era5.copernicus_mx_1km_200..200cm_2019.04.01..2019.04.30_eumap_epsg3035_v0.1.tif'\n",
    "\n",
    "# ttprint('de')\n",
    "# polys = gpd.read_file(\"./material/nuts_de_2021.gpkg\")         \n",
    "# with rasterio.open(rtif) as src:\n",
    "#     # out_image → ndarray (bands, rows, cols)\n",
    "#     # out_transform → affine transform for the masked array\n",
    "#     out_image, out_transform = mask(src, polys.geometry, crop=True)\n",
    "#     out_image = out_image[0]                    # assume one-band raster\n",
    "#     crs = src.crs                               # keep raster CRS\n",
    "\n",
    "# height, width = out_image.shape\n",
    "# rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "# xs, ys = rasterio.transform.xy(out_transform, rows, cols, offset='center')\n",
    "# df = pd.DataFrame({\n",
    "#     \"x\": np.array(xs).flatten(),\n",
    "#     \"y\": np.array(ys).flatten(),\n",
    "#     \"value\": out_image.flatten()\n",
    "# })\n",
    "\n",
    "# de = gpd.GeoDataFrame(\n",
    "#         df,\n",
    "#         geometry=[Point(x, y) for x, y in zip(df.x, df.y)],\n",
    "#         crs=crs\n",
    "# )\n",
    "\n",
    "# ttprint('es')\n",
    "# polys = gpd.read_file(\"./material/nuts_es_2021.gpkg\")         \n",
    "# with rasterio.open(rtif) as src:\n",
    "#     out_image, out_transform = mask(src, polys.geometry, crop=True)\n",
    "#     out_image = out_image[0]                    # assume one-band raster\n",
    "#     crs = src.crs                               # keep raster CRS\n",
    "\n",
    "# height, width = out_image.shape\n",
    "# rows, cols = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')\n",
    "# xs, ys = rasterio.transform.xy(out_transform, rows, cols, offset='center')\n",
    "# df = pd.DataFrame({\n",
    "#     \"x\": np.array(xs).flatten(),\n",
    "#     \"y\": np.array(ys).flatten(),\n",
    "#     \"value\": out_image.flatten()\n",
    "# })\n",
    "# es = gpd.GeoDataFrame(\n",
    "#         df,\n",
    "#         geometry=[Point(x, y) for x, y in zip(df.x, df.y)],\n",
    "#         crs=crs\n",
    "# )\n",
    "\n",
    "# ttprint('finish')\n",
    "\n",
    "# de['nuts0'] = 'DE'\n",
    "# es['nuts0'] = 'ES'\n",
    "\n",
    "# agg_pixel = pd.concat([de,es])\n",
    "# agg_pixel = agg_pixel.drop(columns=['geometry','value'])\n",
    "# agg_pixel.to_parquet('./material/pixel_agg.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ddd13-8cf9-4ab9-8edb-799d33b7d206",
   "metadata": {
    "tags": []
   },
   "source": [
    "## read back in the overlaid version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb533c3-89c2-48aa-bb6b-0b8bf787237b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7678990, 79)\n",
      "(2335589, 79)\n"
     ]
    }
   ],
   "source": [
    "tgt = 'soc_log1p'\n",
    "prop = 'soc'\n",
    "# df = pd.read_parquet('./pixel_agg.pq')\n",
    "\n",
    "covs = pd.read_csv(f'./metric/feature_selected_soc_{version}.txt', header=None)[0].tolist() \n",
    "\n",
    "df = pd.read_parquet(f'./material/agg.pixel.tmp_overlaid_{version}.pq')\n",
    "print(df.shape)\n",
    "dff = df.dropna(subset=covs,how='any')\n",
    "print(dff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b39ca5-c764-4903-bbf8-cd5586fd59bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7678990, 79)\n",
      "(2335589, 79)\n"
     ]
    }
   ],
   "source": [
    "tgt = 'soc_log1p'\n",
    "\n",
    "# df = pd.read_parquet('./pixel_agg.pq')\n",
    "\n",
    "covs = pd.read_csv(f'./feature_selected_soc_{version}.txt', header=None)[0].tolist() \n",
    "\n",
    "df = pd.read_parquet(f'./agg.pixel.tmp_overlaid_{version}.pq')\n",
    "print(df.shape)\n",
    "dff = df.dropna(subset=covs,how='any')\n",
    "print(dff.shape)\n",
    "# dff = dff.groupby('id').filter(lambda x: len(x) >= 3).reset_index(drop=True)\n",
    "# print(dff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5843206-30d7-4a05-a9b2-8692fa36e513",
   "metadata": {},
   "source": [
    "## cast the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c653fd-e9c9-4193-a6c4-1a0e9306a636",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:08] casting the model\n",
      "[22:02:24] finish casting\n"
     ]
    }
   ],
   "source": [
    "# read in model\n",
    "model = joblib.load(f'./model/model_rf.soc_ccc_{version}.joblib')\n",
    "model.n_jobs = 90\n",
    "\n",
    "# use all the points to train model\n",
    "train = pd.read_parquet(f'./material/soc.topsoil_organized_{version}.pq')\n",
    "train[tgt] = np.log1p(train[prop])\n",
    "train = train.dropna(subset=covs+[tgt],how='any').reset_index(drop=True)\n",
    "\n",
    "# fit\n",
    "model.fit(train[covs], train[tgt])\n",
    "\n",
    "# cast the model\n",
    "import copy\n",
    "from trees_rf import cast_tree_rf, cast_node_rf, pad_leaf_outputs_to_array\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names, but\")\n",
    "ttprint('casting the model')\n",
    "model_copy = copy.deepcopy(model)\n",
    "modeln = cast_node_rf(model_copy, train[covs], train[tgt])\n",
    "ttprint('finish casting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73379f4d-7c0e-4d97-8124-8236f4473404",
   "metadata": {},
   "source": [
    "## start prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa33636-d691-4ae7-aff7-5dc179a2556f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:24] start prediction\n",
      "[22:02:26] finish prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5277/1822879946.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dff[f'pred'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "ttprint('start prediction')\n",
    "y_pred = model.predict(dff[covs])\n",
    "y_pred = np.expm1(y_pred)\n",
    "dff[f'pred'] = y_pred\n",
    "ttprint('finish prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3e9873-c5f9-4010-b428-302cf63ab179",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:02:26] In total 234 chunks\n",
      "[22:02:26] chunk 1/234 (0:10000)--------\n",
      "[22:02:26] start predicting and padding\n",
      "[22:03:17] start calculating std\n",
      "[22:03:17] chunk 2/234 (10000:20000)--------\n",
      "[22:03:17] start predicting and padding\n",
      "[22:04:04] start calculating std\n",
      "[22:04:04] chunk 3/234 (20000:30000)--------\n",
      "[22:04:04] start predicting and padding\n",
      "[22:04:50] start calculating std\n",
      "[22:04:51] chunk 4/234 (30000:40000)--------\n",
      "[22:04:51] start predicting and padding\n",
      "[22:05:37] start calculating std\n",
      "[22:05:38] chunk 5/234 (40000:50000)--------\n",
      "[22:05:38] start predicting and padding\n",
      "[22:06:24] start calculating std\n",
      "[22:06:24] chunk 6/234 (50000:60000)--------\n",
      "[22:06:24] start predicting and padding\n",
      "[22:07:11] start calculating std\n",
      "[22:07:11] chunk 7/234 (60000:70000)--------\n",
      "[22:07:11] start predicting and padding\n",
      "[22:07:58] start calculating std\n",
      "[22:07:58] chunk 8/234 (70000:80000)--------\n",
      "[22:07:58] start predicting and padding\n",
      "[22:08:45] start calculating std\n",
      "[22:08:46] chunk 9/234 (80000:90000)--------\n",
      "[22:08:46] start predicting and padding\n",
      "[22:09:33] start calculating std\n",
      "[22:09:33] chunk 10/234 (90000:100000)--------\n",
      "[22:09:33] start predicting and padding\n",
      "[22:10:20] start calculating std\n",
      "[22:10:20] chunk 11/234 (100000:110000)--------\n",
      "[22:10:20] start predicting and padding\n",
      "[22:11:07] start calculating std\n",
      "[22:11:07] chunk 12/234 (110000:120000)--------\n",
      "[22:11:07] start predicting and padding\n",
      "[22:11:54] start calculating std\n",
      "[22:11:55] chunk 13/234 (120000:130000)--------\n",
      "[22:11:55] start predicting and padding\n",
      "[22:12:42] start calculating std\n",
      "[22:12:42] chunk 14/234 (130000:140000)--------\n",
      "[22:12:42] start predicting and padding\n",
      "[22:13:29] start calculating std\n",
      "[22:13:29] chunk 15/234 (140000:150000)--------\n",
      "[22:13:29] start predicting and padding\n",
      "[22:14:16] start calculating std\n",
      "[22:14:17] chunk 16/234 (150000:160000)--------\n",
      "[22:14:17] start predicting and padding\n",
      "[22:15:04] start calculating std\n",
      "[22:15:04] chunk 17/234 (160000:170000)--------\n",
      "[22:15:04] start predicting and padding\n",
      "[22:15:51] start calculating std\n",
      "[22:15:51] chunk 18/234 (170000:180000)--------\n",
      "[22:15:51] start predicting and padding\n",
      "[22:16:39] start calculating std\n",
      "[22:16:39] chunk 19/234 (180000:190000)--------\n",
      "[22:16:39] start predicting and padding\n",
      "[22:17:26] start calculating std\n",
      "[22:17:26] chunk 20/234 (190000:200000)--------\n",
      "[22:17:26] start predicting and padding\n",
      "[22:18:14] start calculating std\n",
      "[22:18:14] chunk 21/234 (200000:210000)--------\n",
      "[22:18:14] start predicting and padding\n",
      "[22:19:01] start calculating std\n",
      "[22:19:02] chunk 22/234 (210000:220000)--------\n",
      "[22:19:02] start predicting and padding\n",
      "[22:19:49] start calculating std\n",
      "[22:19:50] chunk 23/234 (220000:230000)--------\n",
      "[22:19:50] start predicting and padding\n",
      "[22:20:37] start calculating std\n",
      "[22:20:38] chunk 24/234 (230000:240000)--------\n",
      "[22:20:38] start predicting and padding\n",
      "[22:21:25] start calculating std\n",
      "[22:21:25] chunk 25/234 (240000:250000)--------\n",
      "[22:21:25] start predicting and padding\n",
      "[22:22:12] start calculating std\n",
      "[22:22:13] chunk 26/234 (250000:260000)--------\n",
      "[22:22:13] start predicting and padding\n",
      "[22:23:00] start calculating std\n",
      "[22:23:01] chunk 27/234 (260000:270000)--------\n",
      "[22:23:01] start predicting and padding\n",
      "[22:23:49] start calculating std\n",
      "[22:23:49] chunk 28/234 (270000:280000)--------\n",
      "[22:23:49] start predicting and padding\n",
      "[22:24:37] start calculating std\n",
      "[22:24:37] chunk 29/234 (280000:290000)--------\n",
      "[22:24:37] start predicting and padding\n",
      "[22:25:25] start calculating std\n",
      "[22:25:25] chunk 30/234 (290000:300000)--------\n",
      "[22:25:25] start predicting and padding\n",
      "[22:26:13] start calculating std\n",
      "[22:26:14] chunk 31/234 (300000:310000)--------\n",
      "[22:26:14] start predicting and padding\n",
      "[22:27:02] start calculating std\n",
      "[22:27:02] chunk 32/234 (310000:320000)--------\n",
      "[22:27:02] start predicting and padding\n",
      "[22:27:50] start calculating std\n",
      "[22:27:51] chunk 33/234 (320000:330000)--------\n",
      "[22:27:51] start predicting and padding\n",
      "[22:28:39] start calculating std\n",
      "[22:28:40] chunk 34/234 (330000:340000)--------\n",
      "[22:28:40] start predicting and padding\n",
      "[22:29:27] start calculating std\n",
      "[22:29:28] chunk 35/234 (340000:350000)--------\n",
      "[22:29:28] start predicting and padding\n",
      "[22:30:16] start calculating std\n",
      "[22:30:16] chunk 36/234 (350000:360000)--------\n",
      "[22:30:16] start predicting and padding\n",
      "[22:31:04] start calculating std\n",
      "[22:31:05] chunk 37/234 (360000:370000)--------\n",
      "[22:31:05] start predicting and padding\n",
      "[22:31:53] start calculating std\n",
      "[22:31:53] chunk 38/234 (370000:380000)--------\n",
      "[22:31:53] start predicting and padding\n",
      "[22:32:41] start calculating std\n",
      "[22:32:42] chunk 39/234 (380000:390000)--------\n",
      "[22:32:42] start predicting and padding\n",
      "[22:33:30] start calculating std\n",
      "[22:33:30] chunk 40/234 (390000:400000)--------\n",
      "[22:33:30] start predicting and padding\n",
      "[22:34:17] start calculating std\n",
      "[22:34:18] chunk 41/234 (400000:410000)--------\n",
      "[22:34:18] start predicting and padding\n",
      "[22:35:06] start calculating std\n",
      "[22:35:06] chunk 42/234 (410000:420000)--------\n",
      "[22:35:06] start predicting and padding\n",
      "[22:35:54] start calculating std\n",
      "[22:35:54] chunk 43/234 (420000:430000)--------\n",
      "[22:35:54] start predicting and padding\n",
      "[22:36:42] start calculating std\n",
      "[22:36:42] chunk 44/234 (430000:440000)--------\n",
      "[22:36:42] start predicting and padding\n",
      "[22:37:29] start calculating std\n",
      "[22:37:30] chunk 45/234 (440000:450000)--------\n",
      "[22:37:30] start predicting and padding\n",
      "[22:38:17] start calculating std\n",
      "[22:38:17] chunk 46/234 (450000:460000)--------\n",
      "[22:38:17] start predicting and padding\n",
      "[22:39:04] start calculating std\n",
      "[22:39:04] chunk 47/234 (460000:470000)--------\n",
      "[22:39:04] start predicting and padding\n",
      "[22:39:51] start calculating std\n",
      "[22:39:51] chunk 48/234 (470000:480000)--------\n",
      "[22:39:51] start predicting and padding\n",
      "[22:40:37] start calculating std\n",
      "[22:40:37] chunk 49/234 (480000:490000)--------\n",
      "[22:40:37] start predicting and padding\n",
      "[22:41:24] start calculating std\n",
      "[22:41:24] chunk 50/234 (490000:500000)--------\n",
      "[22:41:24] start predicting and padding\n",
      "[22:42:12] start calculating std\n",
      "[22:42:12] chunk 51/234 (500000:510000)--------\n",
      "[22:42:12] start predicting and padding\n",
      "[22:42:59] start calculating std\n",
      "[22:43:00] chunk 52/234 (510000:520000)--------\n",
      "[22:43:00] start predicting and padding\n",
      "[22:43:47] start calculating std\n",
      "[22:43:48] chunk 53/234 (520000:530000)--------\n",
      "[22:43:48] start predicting and padding\n",
      "[22:44:35] start calculating std\n",
      "[22:44:36] chunk 54/234 (530000:540000)--------\n",
      "[22:44:36] start predicting and padding\n",
      "[22:45:23] start calculating std\n",
      "[22:45:24] chunk 55/234 (540000:550000)--------\n",
      "[22:45:24] start predicting and padding\n",
      "[22:46:12] start calculating std\n",
      "[22:46:12] chunk 56/234 (550000:560000)--------\n",
      "[22:46:12] start predicting and padding\n",
      "[22:47:00] start calculating std\n",
      "[22:47:01] chunk 57/234 (560000:570000)--------\n",
      "[22:47:01] start predicting and padding\n",
      "[22:47:49] start calculating std\n",
      "[22:47:49] chunk 58/234 (570000:580000)--------\n",
      "[22:47:49] start predicting and padding\n",
      "[22:48:37] start calculating std\n",
      "[22:48:37] chunk 59/234 (580000:590000)--------\n",
      "[22:48:37] start predicting and padding\n",
      "[22:49:25] start calculating std\n",
      "[22:49:26] chunk 60/234 (590000:600000)--------\n",
      "[22:49:26] start predicting and padding\n",
      "[22:50:13] start calculating std\n",
      "[22:50:13] chunk 61/234 (600000:610000)--------\n",
      "[22:50:13] start predicting and padding\n",
      "[22:51:01] start calculating std\n",
      "[22:51:02] chunk 62/234 (610000:620000)--------\n",
      "[22:51:02] start predicting and padding\n",
      "[22:51:49] start calculating std\n",
      "[22:51:50] chunk 63/234 (620000:630000)--------\n",
      "[22:51:50] start predicting and padding\n",
      "[22:52:38] start calculating std\n",
      "[22:52:38] chunk 64/234 (630000:640000)--------\n",
      "[22:52:38] start predicting and padding\n",
      "[22:53:26] start calculating std\n",
      "[22:53:26] chunk 65/234 (640000:650000)--------\n",
      "[22:53:26] start predicting and padding\n",
      "[22:54:14] start calculating std\n",
      "[22:54:14] chunk 66/234 (650000:660000)--------\n",
      "[22:54:14] start predicting and padding\n",
      "[22:55:02] start calculating std\n",
      "[22:55:02] chunk 67/234 (660000:670000)--------\n",
      "[22:55:02] start predicting and padding\n",
      "[22:55:50] start calculating std\n",
      "[22:55:50] chunk 68/234 (670000:680000)--------\n",
      "[22:55:50] start predicting and padding\n",
      "[22:56:38] start calculating std\n",
      "[22:56:38] chunk 69/234 (680000:690000)--------\n",
      "[22:56:38] start predicting and padding\n",
      "[22:57:26] start calculating std\n",
      "[22:57:26] chunk 70/234 (690000:700000)--------\n",
      "[22:57:26] start predicting and padding\n",
      "[22:58:13] start calculating std\n",
      "[22:58:14] chunk 71/234 (700000:710000)--------\n",
      "[22:58:14] start predicting and padding\n",
      "[22:59:01] start calculating std\n",
      "[22:59:01] chunk 72/234 (710000:720000)--------\n",
      "[22:59:01] start predicting and padding\n",
      "[22:59:48] start calculating std\n",
      "[22:59:49] chunk 73/234 (720000:730000)--------\n",
      "[22:59:49] start predicting and padding\n",
      "[23:00:36] start calculating std\n",
      "[23:00:36] chunk 74/234 (730000:740000)--------\n",
      "[23:00:36] start predicting and padding\n",
      "[23:01:23] start calculating std\n",
      "[23:01:24] chunk 75/234 (740000:750000)--------\n",
      "[23:01:24] start predicting and padding\n",
      "[23:02:11] start calculating std\n",
      "[23:02:12] chunk 76/234 (750000:760000)--------\n",
      "[23:02:12] start predicting and padding\n",
      "[23:02:59] start calculating std\n",
      "[23:02:59] chunk 77/234 (760000:770000)--------\n",
      "[23:02:59] start predicting and padding\n",
      "[23:03:46] start calculating std\n",
      "[23:03:47] chunk 78/234 (770000:780000)--------\n",
      "[23:03:47] start predicting and padding\n",
      "[23:04:34] start calculating std\n",
      "[23:04:34] chunk 79/234 (780000:790000)--------\n",
      "[23:04:34] start predicting and padding\n",
      "[23:05:21] start calculating std\n",
      "[23:05:22] chunk 80/234 (790000:800000)--------\n",
      "[23:05:22] start predicting and padding\n",
      "[23:06:09] start calculating std\n",
      "[23:06:09] chunk 81/234 (800000:810000)--------\n",
      "[23:06:09] start predicting and padding\n",
      "[23:06:58] start calculating std\n",
      "[23:06:58] chunk 82/234 (810000:820000)--------\n",
      "[23:06:58] start predicting and padding\n",
      "[23:07:46] start calculating std\n",
      "[23:07:46] chunk 83/234 (820000:830000)--------\n",
      "[23:07:46] start predicting and padding\n",
      "[23:08:33] start calculating std\n",
      "[23:08:33] chunk 84/234 (830000:840000)--------\n",
      "[23:08:33] start predicting and padding\n",
      "[23:09:21] start calculating std\n",
      "[23:09:21] chunk 85/234 (840000:850000)--------\n",
      "[23:09:21] start predicting and padding\n",
      "[23:10:08] start calculating std\n",
      "[23:10:08] chunk 86/234 (850000:860000)--------\n",
      "[23:10:08] start predicting and padding\n",
      "[23:10:55] start calculating std\n",
      "[23:10:56] chunk 87/234 (860000:870000)--------\n",
      "[23:10:56] start predicting and padding\n",
      "[23:11:43] start calculating std\n",
      "[23:11:43] chunk 88/234 (870000:880000)--------\n",
      "[23:11:43] start predicting and padding\n",
      "[23:12:31] start calculating std\n",
      "[23:12:31] chunk 89/234 (880000:890000)--------\n",
      "[23:12:31] start predicting and padding\n",
      "[23:13:18] start calculating std\n",
      "[23:13:19] chunk 90/234 (890000:900000)--------\n",
      "[23:13:19] start predicting and padding\n",
      "[23:14:06] start calculating std\n",
      "[23:14:06] chunk 91/234 (900000:910000)--------\n",
      "[23:14:06] start predicting and padding\n",
      "[23:14:54] start calculating std\n",
      "[23:14:54] chunk 92/234 (910000:920000)--------\n",
      "[23:14:54] start predicting and padding\n",
      "[23:15:42] start calculating std\n",
      "[23:15:42] chunk 93/234 (920000:930000)--------\n",
      "[23:15:42] start predicting and padding\n",
      "[23:16:29] start calculating std\n",
      "[23:16:30] chunk 94/234 (930000:940000)--------\n",
      "[23:16:30] start predicting and padding\n",
      "[23:17:17] start calculating std\n",
      "[23:17:18] chunk 95/234 (940000:950000)--------\n",
      "[23:17:18] start predicting and padding\n",
      "[23:18:05] start calculating std\n",
      "[23:18:06] chunk 96/234 (950000:960000)--------\n",
      "[23:18:06] start predicting and padding\n",
      "[23:18:53] start calculating std\n",
      "[23:18:53] chunk 97/234 (960000:970000)--------\n",
      "[23:18:53] start predicting and padding\n",
      "[23:19:41] start calculating std\n",
      "[23:19:41] chunk 98/234 (970000:980000)--------\n",
      "[23:19:41] start predicting and padding\n",
      "[23:20:28] start calculating std\n",
      "[23:20:28] chunk 99/234 (980000:990000)--------\n",
      "[23:20:28] start predicting and padding\n",
      "[23:21:16] start calculating std\n",
      "[23:21:16] chunk 100/234 (990000:1000000)--------\n",
      "[23:21:16] start predicting and padding\n",
      "[23:22:03] start calculating std\n",
      "[23:22:03] chunk 101/234 (1000000:1010000)--------\n",
      "[23:22:03] start predicting and padding\n",
      "[23:22:50] start calculating std\n",
      "[23:22:51] chunk 102/234 (1010000:1020000)--------\n",
      "[23:22:51] start predicting and padding\n",
      "[23:23:38] start calculating std\n",
      "[23:23:38] chunk 103/234 (1020000:1030000)--------\n",
      "[23:23:38] start predicting and padding\n",
      "[23:24:26] start calculating std\n",
      "[23:24:26] chunk 104/234 (1030000:1040000)--------\n",
      "[23:24:26] start predicting and padding\n",
      "[23:25:14] start calculating std\n",
      "[23:25:14] chunk 105/234 (1040000:1050000)--------\n",
      "[23:25:14] start predicting and padding\n",
      "[23:26:01] start calculating std\n",
      "[23:26:01] chunk 106/234 (1050000:1060000)--------\n",
      "[23:26:01] start predicting and padding\n",
      "[23:26:48] start calculating std\n",
      "[23:26:48] chunk 107/234 (1060000:1070000)--------\n",
      "[23:26:48] start predicting and padding\n",
      "[23:27:35] start calculating std\n",
      "[23:27:36] chunk 108/234 (1070000:1080000)--------\n",
      "[23:27:36] start predicting and padding\n",
      "[23:28:22] start calculating std\n",
      "[23:28:22] chunk 109/234 (1080000:1090000)--------\n",
      "[23:28:22] start predicting and padding\n",
      "[23:29:09] start calculating std\n",
      "[23:29:10] chunk 110/234 (1090000:1100000)--------\n",
      "[23:29:10] start predicting and padding\n",
      "[23:29:57] start calculating std\n",
      "[23:29:57] chunk 111/234 (1100000:1110000)--------\n",
      "[23:29:57] start predicting and padding\n",
      "[23:30:44] start calculating std\n",
      "[23:30:44] chunk 112/234 (1110000:1120000)--------\n",
      "[23:30:44] start predicting and padding\n",
      "[23:31:31] start calculating std\n",
      "[23:31:31] chunk 113/234 (1120000:1130000)--------\n",
      "[23:31:31] start predicting and padding\n",
      "[23:32:18] start calculating std\n",
      "[23:32:18] chunk 114/234 (1130000:1140000)--------\n",
      "[23:32:18] start predicting and padding\n",
      "[23:33:05] start calculating std\n",
      "[23:33:05] chunk 115/234 (1140000:1150000)--------\n",
      "[23:33:05] start predicting and padding\n",
      "[23:33:52] start calculating std\n",
      "[23:33:52] chunk 116/234 (1150000:1160000)--------\n",
      "[23:33:52] start predicting and padding\n",
      "[23:34:38] start calculating std\n",
      "[23:34:39] chunk 117/234 (1160000:1170000)--------\n",
      "[23:34:39] start predicting and padding\n",
      "[23:35:25] start calculating std\n",
      "[23:35:25] chunk 118/234 (1170000:1180000)--------\n",
      "[23:35:25] start predicting and padding\n",
      "[23:36:12] start calculating std\n",
      "[23:36:12] chunk 119/234 (1180000:1190000)--------\n",
      "[23:36:12] start predicting and padding\n",
      "[23:36:58] start calculating std\n",
      "[23:36:58] chunk 120/234 (1190000:1200000)--------\n",
      "[23:36:58] start predicting and padding\n",
      "[23:37:44] start calculating std\n",
      "[23:37:45] chunk 121/234 (1200000:1210000)--------\n",
      "[23:37:45] start predicting and padding\n",
      "[23:38:31] start calculating std\n",
      "[23:38:31] chunk 122/234 (1210000:1220000)--------\n",
      "[23:38:31] start predicting and padding\n",
      "[23:39:18] start calculating std\n",
      "[23:39:18] chunk 123/234 (1220000:1230000)--------\n",
      "[23:39:18] start predicting and padding\n",
      "[23:40:05] start calculating std\n",
      "[23:40:05] chunk 124/234 (1230000:1240000)--------\n",
      "[23:40:05] start predicting and padding\n",
      "[23:40:52] start calculating std\n",
      "[23:40:52] chunk 125/234 (1240000:1250000)--------\n",
      "[23:40:52] start predicting and padding\n",
      "[23:41:39] start calculating std\n",
      "[23:41:39] chunk 126/234 (1250000:1260000)--------\n",
      "[23:41:39] start predicting and padding\n",
      "[23:42:26] start calculating std\n",
      "[23:42:26] chunk 127/234 (1260000:1270000)--------\n",
      "[23:42:26] start predicting and padding\n",
      "[23:43:13] start calculating std\n",
      "[23:43:13] chunk 128/234 (1270000:1280000)--------\n",
      "[23:43:13] start predicting and padding\n",
      "[23:43:59] start calculating std\n",
      "[23:44:00] chunk 129/234 (1280000:1290000)--------\n",
      "[23:44:00] start predicting and padding\n",
      "[23:44:47] start calculating std\n",
      "[23:44:47] chunk 130/234 (1290000:1300000)--------\n",
      "[23:44:47] start predicting and padding\n",
      "[23:45:33] start calculating std\n",
      "[23:45:34] chunk 131/234 (1300000:1310000)--------\n",
      "[23:45:34] start predicting and padding\n",
      "[23:46:20] start calculating std\n",
      "[23:46:21] chunk 132/234 (1310000:1320000)--------\n",
      "[23:46:21] start predicting and padding\n",
      "[23:47:07] start calculating std\n",
      "[23:47:08] chunk 133/234 (1320000:1330000)--------\n",
      "[23:47:08] start predicting and padding\n",
      "[23:47:54] start calculating std\n",
      "[23:47:55] chunk 134/234 (1330000:1340000)--------\n",
      "[23:47:55] start predicting and padding\n",
      "[23:48:42] start calculating std\n",
      "[23:48:42] chunk 135/234 (1340000:1350000)--------\n",
      "[23:48:42] start predicting and padding\n",
      "[23:49:29] start calculating std\n",
      "[23:49:30] chunk 136/234 (1350000:1360000)--------\n",
      "[23:49:30] start predicting and padding\n",
      "[23:50:17] start calculating std\n",
      "[23:50:17] chunk 137/234 (1360000:1370000)--------\n",
      "[23:50:17] start predicting and padding\n",
      "[23:51:04] start calculating std\n",
      "[23:51:05] chunk 138/234 (1370000:1380000)--------\n",
      "[23:51:05] start predicting and padding\n",
      "[23:51:52] start calculating std\n",
      "[23:51:53] chunk 139/234 (1380000:1390000)--------\n",
      "[23:51:53] start predicting and padding\n",
      "[23:52:40] start calculating std\n",
      "[23:52:41] chunk 140/234 (1390000:1400000)--------\n",
      "[23:52:41] start predicting and padding\n",
      "[23:53:28] start calculating std\n",
      "[23:53:28] chunk 141/234 (1400000:1410000)--------\n",
      "[23:53:28] start predicting and padding\n",
      "[23:54:16] start calculating std\n",
      "[23:54:16] chunk 142/234 (1410000:1420000)--------\n",
      "[23:54:16] start predicting and padding\n",
      "[23:55:03] start calculating std\n",
      "[23:55:04] chunk 143/234 (1420000:1430000)--------\n",
      "[23:55:04] start predicting and padding\n",
      "[23:55:51] start calculating std\n",
      "[23:55:52] chunk 144/234 (1430000:1440000)--------\n",
      "[23:55:52] start predicting and padding\n",
      "[23:56:39] start calculating std\n",
      "[23:56:40] chunk 145/234 (1440000:1450000)--------\n",
      "[23:56:40] start predicting and padding\n",
      "[23:57:28] start calculating std\n",
      "[23:57:28] chunk 146/234 (1450000:1460000)--------\n",
      "[23:57:28] start predicting and padding\n",
      "[23:58:16] start calculating std\n",
      "[23:58:16] chunk 147/234 (1460000:1470000)--------\n",
      "[23:58:16] start predicting and padding\n",
      "[23:59:04] start calculating std\n",
      "[23:59:05] chunk 148/234 (1470000:1480000)--------\n",
      "[23:59:05] start predicting and padding\n",
      "[23:59:53] start calculating std\n",
      "[23:59:54] chunk 149/234 (1480000:1490000)--------\n",
      "[23:59:54] start predicting and padding\n",
      "[00:00:42] start calculating std\n",
      "[00:00:42] chunk 150/234 (1490000:1500000)--------\n",
      "[00:00:42] start predicting and padding\n",
      "[00:01:30] start calculating std\n",
      "[00:01:31] chunk 151/234 (1500000:1510000)--------\n",
      "[00:01:31] start predicting and padding\n",
      "[00:02:19] start calculating std\n",
      "[00:02:19] chunk 152/234 (1510000:1520000)--------\n",
      "[00:02:19] start predicting and padding\n",
      "[00:03:07] start calculating std\n",
      "[00:03:08] chunk 153/234 (1520000:1530000)--------\n",
      "[00:03:08] start predicting and padding\n",
      "[00:03:56] start calculating std\n",
      "[00:03:57] chunk 154/234 (1530000:1540000)--------\n",
      "[00:03:57] start predicting and padding\n",
      "[00:04:45] start calculating std\n",
      "[00:04:46] chunk 155/234 (1540000:1550000)--------\n",
      "[00:04:46] start predicting and padding\n",
      "[00:05:34] start calculating std\n",
      "[00:05:34] chunk 156/234 (1550000:1560000)--------\n",
      "[00:05:34] start predicting and padding\n",
      "[00:06:23] start calculating std\n",
      "[00:06:23] chunk 157/234 (1560000:1570000)--------\n",
      "[00:06:23] start predicting and padding\n",
      "[00:07:11] start calculating std\n",
      "[00:07:11] chunk 158/234 (1570000:1580000)--------\n",
      "[00:07:11] start predicting and padding\n",
      "[00:07:59] start calculating std\n",
      "[00:08:00] chunk 159/234 (1580000:1590000)--------\n",
      "[00:08:00] start predicting and padding\n",
      "[00:08:47] start calculating std\n",
      "[00:08:47] chunk 160/234 (1590000:1600000)--------\n",
      "[00:08:47] start predicting and padding\n",
      "[00:09:34] start calculating std\n",
      "[00:09:35] chunk 161/234 (1600000:1610000)--------\n",
      "[00:09:35] start predicting and padding\n",
      "[00:10:22] start calculating std\n",
      "[00:10:23] chunk 162/234 (1610000:1620000)--------\n",
      "[00:10:23] start predicting and padding\n",
      "[00:11:10] start calculating std\n",
      "[00:11:10] chunk 163/234 (1620000:1630000)--------\n",
      "[00:11:10] start predicting and padding\n",
      "[00:11:57] start calculating std\n",
      "[00:11:57] chunk 164/234 (1630000:1640000)--------\n",
      "[00:11:57] start predicting and padding\n",
      "[00:12:43] start calculating std\n",
      "[00:12:44] chunk 165/234 (1640000:1650000)--------\n",
      "[00:12:44] start predicting and padding\n",
      "[00:13:30] start calculating std\n",
      "[00:13:30] chunk 166/234 (1650000:1660000)--------\n",
      "[00:13:30] start predicting and padding\n",
      "[00:14:17] start calculating std\n",
      "[00:14:18] chunk 167/234 (1660000:1670000)--------\n",
      "[00:14:18] start predicting and padding\n",
      "[00:15:05] start calculating std\n",
      "[00:15:05] chunk 168/234 (1670000:1680000)--------\n",
      "[00:15:05] start predicting and padding\n",
      "[00:15:52] start calculating std\n",
      "[00:15:53] chunk 169/234 (1680000:1690000)--------\n",
      "[00:15:53] start predicting and padding\n",
      "[00:16:40] start calculating std\n",
      "[00:16:41] chunk 170/234 (1690000:1700000)--------\n",
      "[00:16:41] start predicting and padding\n",
      "[00:17:27] start calculating std\n",
      "[00:17:28] chunk 171/234 (1700000:1710000)--------\n",
      "[00:17:28] start predicting and padding\n",
      "[00:18:15] start calculating std\n",
      "[00:18:16] chunk 172/234 (1710000:1720000)--------\n",
      "[00:18:16] start predicting and padding\n",
      "[00:19:03] start calculating std\n",
      "[00:19:04] chunk 173/234 (1720000:1730000)--------\n",
      "[00:19:04] start predicting and padding\n",
      "[00:19:51] start calculating std\n",
      "[00:19:51] chunk 174/234 (1730000:1740000)--------\n",
      "[00:19:51] start predicting and padding\n",
      "[00:20:40] start calculating std\n",
      "[00:20:40] chunk 175/234 (1740000:1750000)--------\n",
      "[00:20:40] start predicting and padding\n",
      "[00:21:27] start calculating std\n",
      "[00:21:28] chunk 176/234 (1750000:1760000)--------\n",
      "[00:21:28] start predicting and padding\n",
      "[00:22:15] start calculating std\n",
      "[00:22:16] chunk 177/234 (1760000:1770000)--------\n",
      "[00:22:16] start predicting and padding\n",
      "[00:23:03] start calculating std\n",
      "[00:23:04] chunk 178/234 (1770000:1780000)--------\n",
      "[00:23:04] start predicting and padding\n",
      "[00:23:51] start calculating std\n",
      "[00:23:52] chunk 179/234 (1780000:1790000)--------\n",
      "[00:23:52] start predicting and padding\n",
      "[00:24:39] start calculating std\n",
      "[00:24:40] chunk 180/234 (1790000:1800000)--------\n",
      "[00:24:40] start predicting and padding\n",
      "[00:25:27] start calculating std\n",
      "[00:25:28] chunk 181/234 (1800000:1810000)--------\n",
      "[00:25:28] start predicting and padding\n",
      "[00:26:15] start calculating std\n",
      "[00:26:16] chunk 182/234 (1810000:1820000)--------\n",
      "[00:26:16] start predicting and padding\n",
      "[00:27:04] start calculating std\n",
      "[00:27:04] chunk 183/234 (1820000:1830000)--------\n",
      "[00:27:04] start predicting and padding\n",
      "[00:27:52] start calculating std\n",
      "[00:27:52] chunk 184/234 (1830000:1840000)--------\n",
      "[00:27:52] start predicting and padding\n",
      "[00:28:40] start calculating std\n",
      "[00:28:40] chunk 185/234 (1840000:1850000)--------\n",
      "[00:28:40] start predicting and padding\n",
      "[00:29:28] start calculating std\n",
      "[00:29:28] chunk 186/234 (1850000:1860000)--------\n",
      "[00:29:28] start predicting and padding\n",
      "[00:30:15] start calculating std\n",
      "[00:30:16] chunk 187/234 (1860000:1870000)--------\n",
      "[00:30:16] start predicting and padding\n",
      "[00:31:03] start calculating std\n",
      "[00:31:03] chunk 188/234 (1870000:1880000)--------\n",
      "[00:31:03] start predicting and padding\n",
      "[00:31:50] start calculating std\n",
      "[00:31:51] chunk 189/234 (1880000:1890000)--------\n",
      "[00:31:51] start predicting and padding\n",
      "[00:32:38] start calculating std\n",
      "[00:32:38] chunk 190/234 (1890000:1900000)--------\n",
      "[00:32:38] start predicting and padding\n",
      "[00:33:26] start calculating std\n",
      "[00:33:26] chunk 191/234 (1900000:1910000)--------\n",
      "[00:33:26] start predicting and padding\n",
      "[00:34:13] start calculating std\n",
      "[00:34:14] chunk 192/234 (1910000:1920000)--------\n",
      "[00:34:14] start predicting and padding\n",
      "[00:35:01] start calculating std\n",
      "[00:35:01] chunk 193/234 (1920000:1930000)--------\n",
      "[00:35:01] start predicting and padding\n",
      "[00:35:48] start calculating std\n",
      "[00:35:49] chunk 194/234 (1930000:1940000)--------\n",
      "[00:35:49] start predicting and padding\n",
      "[00:36:36] start calculating std\n",
      "[00:36:36] chunk 195/234 (1940000:1950000)--------\n",
      "[00:36:36] start predicting and padding\n",
      "[00:37:24] start calculating std\n",
      "[00:37:24] chunk 196/234 (1950000:1960000)--------\n",
      "[00:37:24] start predicting and padding\n",
      "[00:38:11] start calculating std\n",
      "[00:38:12] chunk 197/234 (1960000:1970000)--------\n",
      "[00:38:12] start predicting and padding\n",
      "[00:38:59] start calculating std\n",
      "[00:38:59] chunk 198/234 (1970000:1980000)--------\n",
      "[00:38:59] start predicting and padding\n",
      "[00:39:46] start calculating std\n",
      "[00:39:47] chunk 199/234 (1980000:1990000)--------\n",
      "[00:39:47] start predicting and padding\n",
      "[00:40:34] start calculating std\n",
      "[00:40:34] chunk 200/234 (1990000:2000000)--------\n",
      "[00:40:34] start predicting and padding\n",
      "[00:41:21] start calculating std\n",
      "[00:41:21] chunk 201/234 (2000000:2010000)--------\n",
      "[00:41:21] start predicting and padding\n",
      "[00:42:08] start calculating std\n",
      "[00:42:09] chunk 202/234 (2010000:2020000)--------\n",
      "[00:42:09] start predicting and padding\n",
      "[00:42:56] start calculating std\n",
      "[00:42:56] chunk 203/234 (2020000:2030000)--------\n",
      "[00:42:56] start predicting and padding\n",
      "[00:43:43] start calculating std\n",
      "[00:43:43] chunk 204/234 (2030000:2040000)--------\n",
      "[00:43:43] start predicting and padding\n",
      "[00:44:30] start calculating std\n",
      "[00:44:31] chunk 205/234 (2040000:2050000)--------\n",
      "[00:44:31] start predicting and padding\n",
      "[00:45:18] start calculating std\n",
      "[00:45:18] chunk 206/234 (2050000:2060000)--------\n",
      "[00:45:18] start predicting and padding\n",
      "[00:46:05] start calculating std\n",
      "[00:46:06] chunk 207/234 (2060000:2070000)--------\n",
      "[00:46:06] start predicting and padding\n",
      "[00:46:53] start calculating std\n",
      "[00:46:53] chunk 208/234 (2070000:2080000)--------\n",
      "[00:46:53] start predicting and padding\n",
      "[00:47:40] start calculating std\n",
      "[00:47:40] chunk 209/234 (2080000:2090000)--------\n",
      "[00:47:40] start predicting and padding\n",
      "[00:48:28] start calculating std\n",
      "[00:48:28] chunk 210/234 (2090000:2100000)--------\n",
      "[00:48:28] start predicting and padding\n",
      "[00:49:15] start calculating std\n",
      "[00:49:15] chunk 211/234 (2100000:2110000)--------\n",
      "[00:49:15] start predicting and padding\n",
      "[00:50:02] start calculating std\n",
      "[00:50:03] chunk 212/234 (2110000:2120000)--------\n",
      "[00:50:03] start predicting and padding\n",
      "[00:50:49] start calculating std\n",
      "[00:50:50] chunk 213/234 (2120000:2130000)--------\n",
      "[00:50:50] start predicting and padding\n",
      "[00:51:37] start calculating std\n",
      "[00:51:37] chunk 214/234 (2130000:2140000)--------\n",
      "[00:51:37] start predicting and padding\n",
      "[00:52:24] start calculating std\n",
      "[00:52:25] chunk 215/234 (2140000:2150000)--------\n",
      "[00:52:25] start predicting and padding\n",
      "[00:53:12] start calculating std\n",
      "[00:53:12] chunk 216/234 (2150000:2160000)--------\n",
      "[00:53:12] start predicting and padding\n",
      "[00:53:58] start calculating std\n",
      "[00:53:58] chunk 217/234 (2160000:2170000)--------\n",
      "[00:53:58] start predicting and padding\n",
      "[00:54:46] start calculating std\n",
      "[00:54:47] chunk 218/234 (2170000:2180000)--------\n",
      "[00:54:47] start predicting and padding\n",
      "[00:55:33] start calculating std\n",
      "[00:55:33] chunk 219/234 (2180000:2190000)--------\n",
      "[00:55:33] start predicting and padding\n",
      "[00:56:20] start calculating std\n",
      "[00:56:20] chunk 220/234 (2190000:2200000)--------\n",
      "[00:56:20] start predicting and padding\n",
      "[00:57:07] start calculating std\n",
      "[00:57:08] chunk 221/234 (2200000:2210000)--------\n",
      "[00:57:08] start predicting and padding\n",
      "[00:57:54] start calculating std\n",
      "[00:57:55] chunk 222/234 (2210000:2220000)--------\n",
      "[00:57:55] start predicting and padding\n",
      "[00:58:41] start calculating std\n",
      "[00:58:41] chunk 223/234 (2220000:2230000)--------\n",
      "[00:58:41] start predicting and padding\n",
      "[00:59:28] start calculating std\n",
      "[00:59:28] chunk 224/234 (2230000:2240000)--------\n",
      "[00:59:28] start predicting and padding\n",
      "[01:00:15] start calculating std\n",
      "[01:00:15] chunk 225/234 (2240000:2250000)--------\n",
      "[01:00:15] start predicting and padding\n",
      "[01:01:02] start calculating std\n",
      "[01:01:02] chunk 226/234 (2250000:2260000)--------\n",
      "[01:01:02] start predicting and padding\n",
      "[01:01:49] start calculating std\n",
      "[01:01:49] chunk 227/234 (2260000:2270000)--------\n",
      "[01:01:49] start predicting and padding\n",
      "[01:02:36] start calculating std\n",
      "[01:02:36] chunk 228/234 (2270000:2280000)--------\n",
      "[01:02:36] start predicting and padding\n",
      "[01:03:23] start calculating std\n",
      "[01:03:23] chunk 229/234 (2280000:2290000)--------\n",
      "[01:03:23] start predicting and padding\n",
      "[01:04:10] start calculating std\n",
      "[01:04:10] chunk 230/234 (2290000:2300000)--------\n",
      "[01:04:10] start predicting and padding\n",
      "[01:04:57] start calculating std\n",
      "[01:04:57] chunk 231/234 (2300000:2310000)--------\n",
      "[01:04:57] start predicting and padding\n",
      "[01:05:44] start calculating std\n",
      "[01:05:44] chunk 232/234 (2310000:2320000)--------\n",
      "[01:05:44] start predicting and padding\n",
      "[01:06:31] start calculating std\n",
      "[01:06:31] chunk 233/234 (2320000:2330000)--------\n",
      "[01:06:31] start predicting and padding\n",
      "[01:07:18] start calculating std\n",
      "[01:07:18] chunk 234/234 (2330000:2335589)--------\n",
      "[01:07:18] start predicting and padding\n",
      "[01:07:44] start calculating std\n",
      "[01:07:44] finish all-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5277/101151631.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dff['pred_std'] = np.concatenate(pred_std_chunks)\n"
     ]
    }
   ],
   "source": [
    "# do the predictions in chunck\n",
    "chunk_size = 10000\n",
    "num_chunks = int(np.ceil(len(dff) / chunk_size))\n",
    "\n",
    "pred_std_chunks = []\n",
    "\n",
    "ttprint(f'In total {num_chunks} chunks')\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = min((i + 1) * chunk_size, len(dff))\n",
    "    ttprint(f'chunk {i + 1}/{num_chunks} ({start}:{end})--------')\n",
    "\n",
    "    chunk = dff.iloc[start:end]\n",
    "\n",
    "    ttprint('start predicting and padding')\n",
    "    node_preds_chunk = modeln.predict(chunk[covs])\n",
    "    nodes_chunk = pad_leaf_outputs_to_array(node_preds_chunk, pad_value=np.nan)\n",
    "    nodes_chunk = np.expm1(nodes_chunk)\n",
    "    \n",
    "    ttprint('start calculating std')\n",
    "    std_chunk = np.nanstd(nodes_chunk.T, axis=0)\n",
    "    pred_std_chunks.append(std_chunk)\n",
    "\n",
    "ttprint(f'finish all-------------------------------')\n",
    "\n",
    "dff['pred_std'] = np.concatenate(pred_std_chunks)\n",
    "\n",
    "dff.to_parquet(f'./material/pixel_agg.predicted_all.{version}.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d26ed99-bb39-4669-9e12-d11d97cf4b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuts0</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pred_2009</th>\n",
       "      <th>pred_2018</th>\n",
       "      <th>pred_std_2009</th>\n",
       "      <th>pred_std_2018</th>\n",
       "      <th>ndvi_2009</th>\n",
       "      <th>ndvi_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2684510.0</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2684510.0</td>\n",
       "      <td>46.552999</td>\n",
       "      <td>48.794744</td>\n",
       "      <td>58.786884</td>\n",
       "      <td>51.091045</td>\n",
       "      <td>221.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2685510.0</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2685510.0</td>\n",
       "      <td>64.268494</td>\n",
       "      <td>53.784290</td>\n",
       "      <td>66.555260</td>\n",
       "      <td>65.331993</td>\n",
       "      <td>223.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2686510.0</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2686510.0</td>\n",
       "      <td>46.805534</td>\n",
       "      <td>45.572253</td>\n",
       "      <td>49.646072</td>\n",
       "      <td>50.258842</td>\n",
       "      <td>225.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2687510.0</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2687510.0</td>\n",
       "      <td>48.276807</td>\n",
       "      <td>45.296850</td>\n",
       "      <td>42.862686</td>\n",
       "      <td>40.360771</td>\n",
       "      <td>220.0</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2688510.0</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2688510.0</td>\n",
       "      <td>27.745630</td>\n",
       "      <td>23.858089</td>\n",
       "      <td>27.717691</td>\n",
       "      <td>25.477179</td>\n",
       "      <td>199.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nuts0        lon        lat          x          y  pred_2009  pred_2018  \\\n",
       "0    DE  4031500.0  2684510.0  4031500.0  2684510.0  46.552999  48.794744   \n",
       "1    DE  4031500.0  2685510.0  4031500.0  2685510.0  64.268494  53.784290   \n",
       "2    DE  4031500.0  2686510.0  4031500.0  2686510.0  46.805534  45.572253   \n",
       "3    DE  4031500.0  2687510.0  4031500.0  2687510.0  48.276807  45.296850   \n",
       "4    DE  4031500.0  2688510.0  4031500.0  2688510.0  27.745630  23.858089   \n",
       "\n",
       "   pred_std_2009  pred_std_2018  ndvi_2009  ndvi_2018  \n",
       "0      58.786884      51.091045      221.0      221.0  \n",
       "1      66.555260      65.331993      223.0      226.0  \n",
       "2      49.646072      50.258842      225.0      231.0  \n",
       "3      42.862686      40.360771      220.0      223.0  \n",
       "4      27.717691      25.477179      199.0      194.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dff = pd.read_parquet(f'./material/pixel_agg.predicted_all.{version}.pq')\n",
    "dff = dff.rename(columns={'ndvi_glad.landast.ard2.seasconv.m.yearly_p50_30m_s_YYYY0101_YYYY1231_eu_epsg.3035_v20231127':'ndvi'})\n",
    "\n",
    "out = (\n",
    "    dff\n",
    "    .pivot_table(\n",
    "        index=['nuts0', 'lon', 'lat', 'x', 'y'],\n",
    "        columns='time',\n",
    "        values=['pred', 'pred_std', 'ndvi'],\n",
    "        aggfunc='first'       \n",
    "    )\n",
    "    .dropna(axis=0)           \n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "out.columns = [\n",
    "    f'{c[0]}_{c[1]}' if c[1] else c[0]   \n",
    "    for c in out.columns.to_flat_index()\n",
    "]\n",
    "\n",
    "static_cols = ['nuts0', 'lon', 'lat', 'x', 'y']\n",
    "value_cols  = ['pred_2009', 'pred_2018', 'pred_std_2009', 'pred_std_2018', 'ndvi_2009', 'ndvi_2018']\n",
    "out = out[static_cols + value_cols]\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5846be0-6b72-4e1c-8c11-09d533f93ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "out['change'] = out['pred_2018'] - out['pred_2009']\n",
    "out['noise'] = np.sqrt(out['pred_std_2009']**2 + out['pred_std_2018']**2)\n",
    "out['signal'] = out['change'].abs()\n",
    "out['SNR'] = out['signal']/out['noise']\n",
    "out['ndvi_mean'] = (out['ndvi_2009'] + out['ndvi_2018'])/2\n",
    "out['ndvi_mean'] = (out['ndvi_mean'] - 125)/125\n",
    "out = out.drop(columns=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9248fde6-d3c2-49c3-9662-d7d1c8b0c8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out.to_parquet('./material/agg_pixel_change.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfda959-af14-4846-b040-3cc7145e280f",
   "metadata": {},
   "source": [
    "## save as geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d02da91-c87b-47c4-9cd6-d823aecbdc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(out['lon'], out['lat'])]\n",
    "gdf = gpd.GeoDataFrame(out, geometry=geometry, crs=\"EPSG:3035\")\n",
    "de = gpd.read_file(\"./material/nuts_de_2021.gpkg\")         \n",
    "es = gpd.read_file(\"./material/nuts_es_2021.gpkg\")         \n",
    "poly = gpd.GeoDataFrame(pd.concat([es, de], ignore_index=True), crs=\"EPSG:3035\")\n",
    "gdf = gpd.sjoin(gdf, poly, how=\"inner\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729b7300-a56b-4cf9-a22e-a8d0ffbc6c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nuts0</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>pred_2009</th>\n",
       "      <th>pred_2018</th>\n",
       "      <th>pred_std_2009</th>\n",
       "      <th>pred_std_2018</th>\n",
       "      <th>ndvi_2009</th>\n",
       "      <th>ndvi_2018</th>\n",
       "      <th>change</th>\n",
       "      <th>noise</th>\n",
       "      <th>signal</th>\n",
       "      <th>SNR</th>\n",
       "      <th>ndvi_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2684510.0</td>\n",
       "      <td>46.552999</td>\n",
       "      <td>48.794744</td>\n",
       "      <td>58.786884</td>\n",
       "      <td>51.091045</td>\n",
       "      <td>221.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>2.241745</td>\n",
       "      <td>77.885765</td>\n",
       "      <td>2.241745</td>\n",
       "      <td>0.028782</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2685510.0</td>\n",
       "      <td>64.268494</td>\n",
       "      <td>53.784290</td>\n",
       "      <td>66.555260</td>\n",
       "      <td>65.331993</td>\n",
       "      <td>223.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>-10.484204</td>\n",
       "      <td>93.262383</td>\n",
       "      <td>10.484204</td>\n",
       "      <td>0.112416</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2686510.0</td>\n",
       "      <td>46.805534</td>\n",
       "      <td>45.572253</td>\n",
       "      <td>49.646072</td>\n",
       "      <td>50.258842</td>\n",
       "      <td>225.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>-1.233281</td>\n",
       "      <td>70.644768</td>\n",
       "      <td>1.233281</td>\n",
       "      <td>0.017457</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2687510.0</td>\n",
       "      <td>48.276807</td>\n",
       "      <td>45.296850</td>\n",
       "      <td>42.862686</td>\n",
       "      <td>40.360771</td>\n",
       "      <td>220.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>-2.979957</td>\n",
       "      <td>58.874458</td>\n",
       "      <td>2.979957</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>4031500.0</td>\n",
       "      <td>2688510.0</td>\n",
       "      <td>27.745630</td>\n",
       "      <td>23.858089</td>\n",
       "      <td>27.717691</td>\n",
       "      <td>25.477179</td>\n",
       "      <td>199.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>-3.887541</td>\n",
       "      <td>37.647804</td>\n",
       "      <td>3.887541</td>\n",
       "      <td>0.103261</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nuts0        lon        lat  pred_2009  pred_2018  pred_std_2009  \\\n",
       "0    DE  4031500.0  2684510.0  46.552999  48.794744      58.786884   \n",
       "1    DE  4031500.0  2685510.0  64.268494  53.784290      66.555260   \n",
       "2    DE  4031500.0  2686510.0  46.805534  45.572253      49.646072   \n",
       "3    DE  4031500.0  2687510.0  48.276807  45.296850      42.862686   \n",
       "4    DE  4031500.0  2688510.0  27.745630  23.858089      27.717691   \n",
       "\n",
       "   pred_std_2018  ndvi_2009  ndvi_2018     change      noise     signal  \\\n",
       "0      51.091045      221.0      221.0   2.241745  77.885765   2.241745   \n",
       "1      65.331993      223.0      226.0 -10.484204  93.262383  10.484204   \n",
       "2      50.258842      225.0      231.0  -1.233281  70.644768   1.233281   \n",
       "3      40.360771      220.0      223.0  -2.979957  58.874458   2.979957   \n",
       "4      25.477179      199.0      194.0  -3.887541  37.647804   3.887541   \n",
       "\n",
       "        SNR  ndvi_mean  \n",
       "0  0.028782      0.768  \n",
       "1  0.112416      0.796  \n",
       "2  0.017457      0.824  \n",
       "3  0.050615      0.772  \n",
       "4  0.103261      0.572  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25350758-7a75-4015-a496-4ef0a6d232f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF written to predictions.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "value_col = \"change\"        \n",
    "points_gdf = gdf.dropna(subset=[value_col]) \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  DERIVE GRID RESOLUTION & EXTENT ------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "x_res = 1000    # ≈ pixel width  (e.g. 1000 m)\n",
    "y_res = 1000           # ≈ pixel height (e.g. 1000 m)\n",
    "\n",
    "minx, miny, maxx, maxy = points_gdf.total_bounds\n",
    "\n",
    "# number of pixels in each direction (+1 so last column/row is included)\n",
    "width  = int(round((maxx - minx) / x_res)) + 1\n",
    "height = int(round((maxy - miny) / y_res)) + 1\n",
    "\n",
    "# Affine transform (upper-left corner is half a pixel north-west of first point)\n",
    "transform = from_origin(minx - x_res / 2,   # west-most edge\n",
    "                        maxy + y_res / 2,   # north-most edge\n",
    "                        x_res,\n",
    "                        y_res)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  RASTERIZE POINT VALUES ---------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "shapes = ((geom, val) for geom, val in\n",
    "          zip(points_gdf.geometry, points_gdf[value_col]))\n",
    "\n",
    "raster = rasterize(\n",
    "    shapes=shapes,\n",
    "    out_shape=(height, width),\n",
    "    transform=transform,\n",
    "    fill=np.nan,             # background\n",
    "    dtype=\"float32\"          # change if your data need another type\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  WRITE GeoTIFF -----------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "meta = {\n",
    "    \"driver\":  \"GTiff\",\n",
    "    \"height\":  height,\n",
    "    \"width\":   width,\n",
    "    \"count\":   1,\n",
    "    \"dtype\":   \"float32\",\n",
    "    \"crs\":     points_gdf.crs,   # keep original CRS\n",
    "    \"transform\": transform,\n",
    "    \"nodata\":  np.nan\n",
    "}\n",
    "\n",
    "with rasterio.open(f\"./figure/{value_col}_new.tif\", \"w\", **meta) as dst:\n",
    "    dst.write(raster, 1)\n",
    "\n",
    "print(\"GeoTIFF written to predictions.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ae826-252a-4dc0-b4f3-5884acac667e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
